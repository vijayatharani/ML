# ML-EmotionBasedRecommendationSystem 

This project detects emotions from a video of a user using OpenCV and predicts songs from Spotify corresponding to the user's mood from the emotions detected.


The project develops a detector to determine the mood of the user from a video of their face. This is done using the **Face Emotion Recognizer (FER) library**. The FER library uses a **convolution neural network** to classify emotions into 6 categories: **fear, neutral, happy, sad, anger, and disgust**. The FER library has an accuracy of **98%** on the **FER2013 dataset**.


Finally, the project combines the two parts to create a system that can detect the user's mood and recommend songs that match the user's mood.





